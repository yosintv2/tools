name: Update Sports Feed
on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch: 

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Fetch and Extract Figure Images
        run: |
          mkdir -p data
          curl -sL -A "Mozilla/5.0" "https://english.onlinekhabar.com/category/sports/feed" -o sports_feed.xml
          
          python3 - <<EOF
          import xml.etree.ElementTree as ET
          import json
          import os
          import re

          def clean_text(text):
              if not text: return ""
              return re.sub('<[^<]+?>', '', text).strip()

          try:
              tree = ET.parse('sports_feed.xml')
              root = tree.getroot()
              
              # Define namespaces used in WordPress feeds
              ns = {
                  'content': 'http://purl.org/rss/1.0/modules/content/',
                  'media': 'http://search.yahoo.com/mrss/'
              }

              newly_fetched = []
              for item in root.findall('.//item'):
                  link = item.find('link').text
                  title = item.find('title').text
                  pub_date = item.find('pubDate').text
                  
                  # Extract the CDATA content from <content:encoded>
                  content_encoded = item.find('content:encoded', ns)
                  full_html = content_encoded.text if content_encoded is not None else ""
                  
                  # --- THE FIX: REACHING INTO CDATA ---
                  image_url = "https://via.placeholder.com/1080x1920?text=No+Image+Found"
                  
                  # Search for the exact figure/img structure you mentioned
                  # This regex targets the src inside the wp-block-image figure
                  img_match = re.search(r'class="wp-block-image[^"]*".*?src="([^"]+)"', full_html, re.DOTALL)
                  
                  if img_match:
                      image_url = img_match.group(1)
                  else:
                      # Backup: search for any img tag if the specific class isn't found
                      any_img = re.search(r'<img [^>]*src="([^"]+)"', full_html)
                      if any_img:
                          image_url = any_img.group(1)

                  newly_fetched.append({
                      "id": link,
                      "date": pub_date,
                      "title": {"rendered": title},
                      "featured_image": image_url,
                      "excerpt": {"rendered": clean_text(full_html)[:150] + "..."}
                  })

              # Merge with existing data
              file_path = 'data/sports.json'
              archive = []
              if os.path.exists(file_path):
                  with open(file_path, 'r') as f:
                      try: archive = json.load(f)
                      except: pass

              existing_ids = {post['id'] for post in archive}
              unique_new = [p for p in newly_fetched if p['id'] not in existing_ids]
              
              final_data = unique_new + archive
              
              with open(file_path, 'w') as f:
                  json.dump(final_data[:500], f, indent=2)
                  
              print(f"Successfully added {len(unique_new)} new articles.")

          except Exception as e:
              print(f"Error: {e}")
          EOF

      - name: Commit and Push
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add data/sports.json
          git commit -m "Update: Extracted high-res figure images" || exit 0
          git push
